{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f620956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 2034\n",
      "Test set size: 1353\n",
      "Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "Train labels: {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# 20개의 토픽 중 선택하고자 하는 토픽을 리스트로 생성\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "# 학습 데이터셋을 가져옴\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      # remove를 사용하여 내용에서 힌트가 되는 부분을 삭제, 순수하게 내용만으로 분류\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories = categories)\n",
    "\n",
    "# 평가 데이터셋을 가져옴\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),categories = categories)\n",
    "\n",
    "print('Train set size:', len(newsgroups_train.data))\n",
    "print('Test set size:', len(newsgroups_test.data))\n",
    "print('Selected categories:', newsgroups_train.target_names)\n",
    "print('Train labels:', set(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9896030",
   "metadata": {},
   "source": [
    "- #### .data는 텍스트의 내용을, .target은 숫자로 표시된 라벨(분류)을 의미한다.\n",
    "- #### 라벨은 실행결과에서 나온(코드 작성 순서 아님) categories의 순서대로 번호를 붙인다.\n",
    "- #### 예를 들어서 실행 결과 Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc'] 이거라면 \n",
    "- #### 'alt.atheism' = 라벨 0, 'comp.graphics' = 라벨 1, 이런 순서대로 라벨이 정해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79e29cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set text samples: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "-----------------------------------------------------------\n",
      "Train set label samples: 1\n",
      "-----------------------------------------------------------\n",
      "Test set text samples: TRry the SKywatch project in  Arizona.\n",
      "-----------------------------------------------------------\n",
      "Test set label samples: 2\n"
     ]
    }
   ],
   "source": [
    "print('Train set text samples:', newsgroups_train.data[0])\n",
    "print('-----------------------------------------------------------')\n",
    "print('Train set label samples:', newsgroups_train.target[0])\n",
    "print('-----------------------------------------------------------')\n",
    "print('Test set text samples:', newsgroups_test.data[0])\n",
    "print('-----------------------------------------------------------')\n",
    "print('Test set label samples:', newsgroups_test.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ad9ad",
   "metadata": {},
   "source": [
    "- #### train set[0]의 라벨이 1 이므로 이 텍스트의 내용은 'comp.graphics'의 내용이다.\n",
    "- #### test set[0]의 라벨이 2 이므로 이 텍스트의 내용은 'sci.space'의 내용이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a50541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set text samples: \n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n",
      "-----------------------------------------------------------\n",
      "Train set label samples: 3\n",
      "-----------------------------------------------------------\n",
      "Test set text samples: The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available.\n",
      "-----------------------------------------------------------\n",
      "Test set label samples: 1\n"
     ]
    }
   ],
   "source": [
    "print('Train set text samples:', newsgroups_train.data[1])\n",
    "print('-----------------------------------------------------------')\n",
    "print('Train set label samples:', newsgroups_train.target[1])\n",
    "print('-----------------------------------------------------------')\n",
    "print('Test set text samples:', newsgroups_test.data[1])\n",
    "print('-----------------------------------------------------------')\n",
    "print('Test set label samples:', newsgroups_test.target[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de59b6",
   "metadata": {},
   "source": [
    "- #### .data는 텍스트의 내용을, .target은 숫자로 표시된 라벨(분류)을 의미한다.\n",
    "- #### 라벨은 categories의 순서대로 번호를 붙인다.\n",
    "- #### 예를들어서 categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space'] 이거라면 \n",
    "- #### 'alt.atheism' = 라벨 0, 'talk.religion.misc' = 라벨 1, 이런 순서대로 라벨이 정해진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ba6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test를 추출한 후에 실제로 문서 분류를 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86dd3314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (2034, 2000)\n",
      "Test set dimension: (1353, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_train = newsgroups_train.data\n",
    "y_train = newsgroups_train.target\n",
    "\n",
    "X_test = newsgroups_test.data\n",
    "y_test = newsgroups_test.target\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_cv = cv.fit_transform(X_train) # Train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape)\n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473aaf02",
   "metadata": {},
   "source": [
    "- #### 위의 예제에서 max_features를 이용해 특성의 수를 2,000개로 제한했다.\n",
    "- #### Min_df는 minimum document frequency로 단어가 최소 이 개수만큼의 문서에 나타나야 한다는 것을 의미한다.\n",
    "- #### Min_df = 5뜻은 5개 미만의 문서에서 나타나는 단어는 특성에서 제외한다는 뜻이다.\n",
    "- #### Max_df는 많은 문서에서 공통으로 나타나는 단어를 제외하기 위해 사용한다. \n",
    "- #### Max_df = 0.5의 뜻은 0.5로 문서의 50%를 초과해 나타나는 단어들을 제외하라는 뜻이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a6587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 : 0, 000 : 0, 01 : 0, 04 : 0, 05 : 0, 10 : 0, 100 : 0, 1000 : 0, 11 : 0, 12 : 0, 128 : 0, 129 : 0, 13 : 0, 130 : 0, 14 : 0, 15 : 0, 16 : 0, 17 : 0, 18 : 0, 19 : 0, 1987 : 0, 1988 : 0, 1989 : 0, 1990 : 0, 1991 : 0, 1992 : 0, 1993 : 0, 20 : 0, 200 : 0, 202 : 0, 21 : 0, 22 : 0, 23 : 0, 24 : 0, 25 : 0, 256 : 0, 26 : 0, 27 : 0, 28 : 0, 2d : 0, 30 : 0, 300 : 0, 31 : 0, 32 : 0, 33 : 0, 34 : 0, 35 : 0, 39 : 0, 3d : 0, 40 : 0, 400 : 0, 42 : 0, 45 : 0, 50 : 0, 500 : 0, 60 : 0, 600 : 0, 65 : 0, 70 : 0, 75 : 0, 80 : 0, 800 : 0, 90 : 0, 900 : 0, 91 : 0, 92 : 0, 93 : 0, 95 : 0, _the : 0, ability : 0, able : 1, abortion : 0, about : 1, above : 0, absolute : 0, absolutely : 0, ac : 0, accept : 0, acceptable : 0, accepted : 0, access : 0, according : 0, account : 0, accurate : 0, across : 0, act : 0, action : 0, actions : 0, active : 0, activities : 0, activity : 0, acts : 0, actual : 0, actually : 0, ad : 0, add : 0, added : 0, addition : 0, additional : 0, address : 0, "
     ]
    }
   ],
   "source": [
    "for word, count in zip(cv.get_feature_names_out()[:100],X_train_cv[0].toarray()[0, :100]):\n",
    "    print(word, ':', count, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c9b570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.824\n",
      "Test set score: 0.732\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# 분류기 선언\n",
    "NB_clf = MultinomialNB()\n",
    "\n",
    "# train set을 이용해 분류기 (classifier)를 학습\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "\n",
    "# train set에 대한 예측 정확도를 확인\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "\n",
    "# test set에 대한 예측 정확도를 확인\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcf69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_cv 는 카운트 벡터로 추출된 특성\n",
    "# y_train은 해당 문서에 대한 분류\n",
    "# score()는 학습모형에 대한 평가인 정확도를 말한다.\n",
    "\n",
    "# 위의 결과에서 보면 Train set 정확도가 Test set 정확도보다 높은데, 이는 머신러닝에서 자주 나타나는 과적합 현상이다.\n",
    "# 학습 데이터에 과하게 학습되어 일반화 성능이 떨어진 것을 의미 할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23816036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#First document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
      "#Score document and label in test data: The Vatican library recently made a tour of the US.\n",
      " Can anyone help me in finding a FTP site where this collection is \n",
      " available. 1\n",
      "#Predicted labels: [2 1]\n",
      "#Predicted categories: sci.space comp.graphics\n"
     ]
    }
   ],
   "source": [
    "# 주어진 텍스트에 대해 predict()를 이용하여 분류를 해보자.\n",
    "\n",
    "print(\"#First document and label in test data:\", X_test[0], y_test[0])\n",
    "print(\"#Score document and label in test data:\", X_test[1], y_test[1])\n",
    "\n",
    "pred = NB_clf.predict(X_test_cv[:2])\n",
    "\n",
    "print(\"#Predicted labels:\", pred)\n",
    "print(\n",
    "\"#Predicted categories:\",\n",
    "newsgroups_train.target_names[pred[0]],\n",
    "newsgroups_train.target_names[pred[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0900d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 개선할 방법은?\n",
    "- #### max_features, min_df, max_df와 같은 CountVectorize의 매개변수를 변경. 예를들어 2,000개 대신 더 많은 수의 특성을 사용할 수 있다.\n",
    "- #### 나이브 베이즈의 매개변수를 조절할 수 있다. MultinominalNB는 모델의 복잡도를 조절하는 alpha 매개변수를 가지고 있다. 이 값을 늘리면 통계 데이터가 완만해지고 복잡도가 낮아진다.\n",
    "- #### 나이브 베이즈가 아닌 다른 머신러닝 알고리즘을 시도해 볼 수 있다. \n",
    "- #### CountVectorizer 대신 TfidfVectorizer를 사용해 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer를 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41598b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
